{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import info\n",
    "import requests\n",
    "from requests import Request, Session\n",
    "import numpy as np\n",
    "import io\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import json\n",
    "from aioconnect.helpers import *\n",
    "from dotenv import load_dotenv\n",
    "from os import getenv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aioconnect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(\n",
    "    email: str,\n",
    "    password: str,\n",
    "):\n",
    "    \"\"\"Log into AIO Impact and get a token.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    email : str\n",
    "        Email address of the user account.\n",
    "\n",
    "    password : str\n",
    "        Password of the user account.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Bearer token.\n",
    "\n",
    "    Raises\n",
    "    -------\n",
    "    requests.exceptions.HTTPError\n",
    "        If the username and password are wrong.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> aioconnect.get_token(\n",
    "    >>>     email=\"firstname.lastname@aioneers.com\", password=\"xxx\",\n",
    "    >>> )\n",
    "    \"\"\"\n",
    "\n",
    "    url = getenv(\"CONNECT_URL\") + \"/login\"\n",
    "    payload = json.dumps({\"email\": email, \"password\": password})\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    token = response.json()[\"token\"]\n",
    "\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_correct_credentials():\n",
    "    password = aioconnect.vault_get_secret(\n",
    "        scope=\"aio-data-science-key\", key=\"sebastian-szilvas-aio-impact\"\n",
    "    )\n",
    "\n",
    "    res = get_token(\n",
    "        email=\"sebastian.szilvas@aioneers.com\",\n",
    "        password=f\"{password}\",\n",
    "    )\n",
    "\n",
    "    assert isinstance(res, str)\n",
    "    assert len(res) > 250\n",
    "\n",
    "def test_wrong_password():\n",
    "    try:\n",
    "        res = get_token(\n",
    "            email=\"sebastian.szilvas@aioneers.com\",\n",
    "            password=\"wrong password\",\n",
    "        )\n",
    "    except requests.exceptions.HTTPError as exception:\n",
    "        assert exception.response.status_code == 401\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_correct_credentials()\n",
    "test_wrong_password()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_json(df):\n",
    "    \"\"\"\n",
    "    The function will convert the pandas dataframe to json file.\n",
    "    -----------------------------\n",
    "\n",
    "    Parameters : \n",
    "    -----------------------------\n",
    "    df -> Pandas.DataFrame : It is the dataframe which you want to convert into json format.\n",
    "\n",
    "    Return : \n",
    "    -----------------------------\n",
    "    output -> json : It is the data converted into json format. \n",
    "\n",
    "    \"\"\"\n",
    "    # Checking Conditions\n",
    "\n",
    "    # 1) Unique Columns\n",
    "    if df['externalId'].isna().any() or df['name'].isna().any() or df['actuals value'].isna().any() or df['actuals timestamp'].isna().any():\n",
    "        raise ValueError('Column Names : externalId, name, actuals value and actuals timestamp cannot be kept empty.')\n",
    "    \n",
    "    # Similar ExternalIds should not have same actuals timestamp\n",
    "    df_2 = df.copy()\n",
    "    for i in df_2['externalId'].unique():\n",
    "        temp = df_2[df_2['externalId'] == i]\n",
    "        if temp['actuals timestamp'].nunique() != len(temp['actuals timestamp']):\n",
    "            raise ValueError('There are more than 1 similar actuals timestamp for externalId {0}'.format(i))\n",
    "\n",
    "\n",
    "    # 2) Optional Columns    \n",
    "    if 'projections value' in df.columns and 'projections timestamp' not in df.columns:\n",
    "        raise KeyError('projection timestamp missing for a projection value')\n",
    "    elif 'projections value' not in df.columns and 'projections timestamp' in df.columns:\n",
    "        raise KeyError('projection value missing for a projection timestamp')\n",
    "    elif 'projections value' not in df.columns and 'projections timestamp' not in df.columns:\n",
    "        pass\n",
    "    else:\n",
    "        df['projections value'].replace({\"-\": 0}, inplace=True)\n",
    "        if df['projections timestamp'].nunique() != len(df['projections timestamp']):\n",
    "            raise ValueError('There are more than 1 similar actuals timestamp')\n",
    "\n",
    "    if 'target' in df.columns and 'targetDate' not in df.columns:\n",
    "        raise KeyError('Target date missing for a target value')\n",
    "    elif 'target' not in df.columns and 'targetDate' in df.columns:\n",
    "        raise KeyError('Target value missing for a target date')\n",
    "    elif 'target' not in df.columns and 'targetDate' not in df.columns:\n",
    "        pass\n",
    "    else:\n",
    "        df['target'].replace({\"-\": 0}, inplace=True)\n",
    "\n",
    "    # df_2 = df.drop(['externalId', 'name', 'description', 'actuals value', 'actuals timestamp', 'target value',\n",
    "    #     'target timestamp', 'projections value', 'projections timestamp'], axis=1)\n",
    "    if 'measureId' in df.columns:\n",
    "        if 'initiativeId' in df.columns:\n",
    "\n",
    "            df_2 = df[['initiativeId','measureId']]\n",
    "            m_notnull = pd.notnull(df_2[\"measureId\"])\n",
    "\n",
    "            df_3 = df_2[m_notnull]\n",
    "\n",
    "            if df_3['initiativeId'].isna().any():\n",
    "                raise ValueError('If measureId is provided then initiativeId is mandatory.')\n",
    "        else:\n",
    "            raise ValueError('If measureId is provided then initiativeId is mandatory.')\n",
    "\n",
    "    if 'metricId' in df.columns:    \n",
    "        if 'initiativeId' in df.columns:\n",
    "            \n",
    "            df_4 = df[['initiativeId','metricId']]\n",
    "\n",
    "            i_null = pd.isnull(df_4[\"initiativeId\"])\n",
    "        \n",
    "            df_5 = df_4[i_null]\n",
    "\n",
    "            if df_5['metricId'].isna().any():\n",
    "                raise ValueError('If initiativeId is not provided then metricId should be provided.')\n",
    "        else: \n",
    "            if df['metricId'].isna().any():\n",
    "                raise ValueError('If initiativeId is not provided then metricId should be provided.')\n",
    "    else:\n",
    "        if 'initiativeId' not in df.columns:\n",
    "            raise ValueError('If initiativeId is not provided then metricId should be provided.')\n",
    "        \n",
    "    # Grouping columns\n",
    "    finalList = []\n",
    "    df['actuals value'].replace({\"-\": 0}, inplace=True)\n",
    "\n",
    "    # if 'target' in df.columns:\n",
    "    #     df['target'].replace({\"-\": 0}, inplace=True)\n",
    "\n",
    "    \n",
    "    grouped = df.groupby(['externalId','actuals timestamp'])\n",
    "\n",
    "    for key, value in grouped:\n",
    "        \n",
    "        dictionary = {}\n",
    "\n",
    "        j = grouped.get_group(key).reset_index(drop=True)\n",
    "        dictionary['externalId'] = j.at[0, 'externalId']\n",
    "        dictionary['name'] = j.at[0, 'name']\n",
    "        dictionary['description'] = j.at[0, 'description']\n",
    "\n",
    "        if 'initiativeId' in df.columns:\n",
    "            if not(pd.isna(j.at[0, 'initiativeId'])):\n",
    "                dictionary['initiativeId'] = j.at[0, 'initiativeId']\n",
    "\n",
    "        if 'measureId' in df.columns:\n",
    "            if not(pd.isna(j.at[0, 'measureId'])):\n",
    "                dictionary['measureId'] = j.at[0, 'measureId']\n",
    "\n",
    "        if 'metricId' in df.columns:\n",
    "            if not(pd.isna(j.at[0, 'metricId'])):\n",
    "                dictionary['metricId'] = j.at[0, 'metricId']\n",
    "        \n",
    "        if 'target' in df.columns:\n",
    "            if not(pd.isna(j.at[0, 'target'])):\n",
    "                dictionary['target'] = j.at[0, 'target']\n",
    "                dictionary['targetDate'] = j.at[0, 'targetDate']\n",
    "        \n",
    "        dict_actual = []\n",
    "        dict_projection = []\n",
    "        \n",
    "        anotherDict_actual = {}\n",
    "        anotherDict_projections = {}\n",
    "        \n",
    "        for i in j.index:\n",
    "\n",
    "            anotherDict_actual['value'] = j.at[i, 'actuals value']\n",
    "            anotherDict_actual['timestamp'] = j.at[i, 'actuals timestamp']\n",
    "\n",
    "            if 'projections value' in df.columns:\n",
    "                # print(j.at[i, 'projections value'])\n",
    "                # print(not(pd.isna(j.at[i, 'projections value'])))\n",
    "                if not(pd.isna(j.at[i, 'projections value'])):\n",
    "                    anotherDict_projections['value'] = j.at[i, 'projections value']\n",
    "                    anotherDict_projections['timestamp'] = j.at[i, 'projections timestamp']\n",
    "\n",
    "                    dictionary_copy_projection = anotherDict_projections.copy()\n",
    "                    dict_projection.append(dictionary_copy_projection)\n",
    "\n",
    "                    dictionary['projections'] = dict_projection\n",
    "            \n",
    "            dictionary_copy_actual = anotherDict_actual.copy()\n",
    "            dict_actual.append(dictionary_copy_actual)\n",
    "\n",
    "            # dictionary_copy_projection = anotherDict_projections.copy()\n",
    "            # dict_projection.append(dictionary_copy_projection)\n",
    "            \n",
    "        dictionary['actuals'] = dict_actual\n",
    "        # dictionary['projections'] = dict_projection\n",
    "        \n",
    "        dict_copy = dictionary.copy()\n",
    "        finalList.append(dict_copy)\n",
    "\n",
    "    # Dump the data into output variable\n",
    "    output = json.dumps(finalList, sort_keys = True, indent=4, cls=NumpyEncoder)\n",
    "    # output = json.dumps(finalList, sort_keys = True, indent=4, cls=NumpyEncoder).replace(\"NaN\" , 'null')\n",
    "    \n",
    "    return output\n",
    "\n",
    "class NumpyEncoder(json.JSONEncoder):\n",
    "    \"\"\" Custom encoder for numpy data types \"\"\"\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, (np.int_, np.intc, np.intp, np.int8,\n",
    "                            np.int16, np.int32, np.int64, np.uint8,\n",
    "                            np.uint16, np.uint32, np.uint64)):\n",
    "\n",
    "            return int(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n",
    "            return float(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.complex_, np.complex64, np.complex128)):\n",
    "            return {'real': obj.real, 'imag': obj.imag}\n",
    "\n",
    "        elif isinstance(obj, (np.ndarray,)):\n",
    "            return obj.tolist()\n",
    "\n",
    "        elif isinstance(obj, (np.bool_)):\n",
    "            return bool(obj)\n",
    "\n",
    "        elif isinstance(obj, (np.void)): \n",
    "            return None\n",
    "\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsert_DOT(\n",
    "    token: str,\n",
    "    dataframe: pd.DataFrame,\n",
    "    limit: int = 100\n",
    ") -> list:\n",
    "    \"\"\"Create a new DOT in AIO Impact or update it if the DOT is already existing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token : str\n",
    "        Token which was returned from the user login.\n",
    "\n",
    "    dataframe : Pandas.DataFrame\n",
    "        Dataframe containing DOT details.\n",
    "    \n",
    "    limit : int\n",
    "        integer value that indicates minimum value of DOTs to be sent. By default, the limit is set to 100\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    requests.Response\n",
    "        HTTP response.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> token = aioconnect.get_token(\n",
    "    >>> email=\"firstname.lastname@aioneers.com\", password=\"xxx\",\n",
    "    >>> )\n",
    "    >>> res = aioconnect.upsert_DOT(\n",
    "    >>>     token=token,\n",
    "    >>>     dataframe = df\n",
    "    >>> )\n",
    "    \"\"\"\n",
    "\n",
    "    url = getenv(\"CONNECT_URL\") + \"/dots\"\n",
    "\n",
    "    columns_list = [\n",
    "        \"externalId\",\n",
    "        \"name\",\n",
    "        \"description\",\n",
    "        \"metricId\",\n",
    "        'initiativeId',\n",
    "        'measureId',\n",
    "        \"actuals value\",\n",
    "        \"actuals timestamp\",\n",
    "        \"target\",\n",
    "        \"targetDate\",\n",
    "        \"projections value\",\n",
    "        \"projections timestamp\"\n",
    "    ]\n",
    "\n",
    "    for i in dataframe.columns:\n",
    "        if i not in columns_list:\n",
    "            raise KeyError(\"Columns not correct\")\n",
    "\n",
    "    if len(dataframe)<limit:\n",
    "        limit = len(dataframe)\n",
    "    \n",
    "    for i in range(0, len(dataframe), limit):\n",
    "        slc = dataframe.iloc[i : i + limit]\n",
    "        payload = convert_to_json(slc)\n",
    "\n",
    "        for attempt in range(20):\n",
    "            try:\n",
    "                response = requests.put(\n",
    "                url=url, headers={\"Authorization\": f\"Bearer {token}\",\n",
    "                                    'Content-Type': 'application/json'}, data=payload)\n",
    "                response.raise_for_status()\n",
    "            except requests.exceptions.HTTPError as exception:\n",
    "                print(\"There was a failed attempt\")\n",
    "                print(exception)\n",
    "            else:\n",
    "                break\n",
    "        # print(payload)\n",
    "        # response = requests.put(\n",
    "        #         url=url, headers={\"Authorization\": f\"Bearer {token}\",\n",
    "        #                             'Content-Type': 'application/json'}, data=payload)\n",
    "        # response.raise_for_status()\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "password = aioconnect.vault_get_secret(\n",
    "        scope=\"aio-data-science-key\", key=\"sebastian-szilvas-aio-impact\"\n",
    "    )\n",
    "\n",
    "token = get_token(\n",
    "    email=\"sebastian.szilvas@aioneers.com\",\n",
    "    password=f\"{password}\",\n",
    ")\n",
    "\n",
    "\n",
    "def test_single_DOT_correct_headers():\n",
    "    data = [{\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-05T06:28:30.000Z\",\n",
    "\n",
    "        \"actuals value\": \"-\",\n",
    "\n",
    "        \"description\": \"Test DOT1\",\n",
    "\n",
    "        \"externalId\": \"201\",\n",
    "\n",
    "        \"initiativeId\": np.NaN,\n",
    "\n",
    "        \"measureId\": np.NaN,\n",
    "\n",
    "        \"metricId\": 101,\n",
    "\n",
    "        \"name\": \"Test DOT1\",\n",
    "        \n",
    "        \"target\": 590,\n",
    "        \n",
    "        \"targetDate\": \"2021-07-30T00:00:00+0000\",\n",
    "\n",
    "        \"projections value\": 59,\n",
    "        \n",
    "        \"projections timestamp\": \"2021-07-30T00:00:00+0000\"\n",
    "    },\n",
    "    {\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-05T06:28:30.000Z\",\n",
    "\n",
    "        \"actuals value\": 291.2,\n",
    "\n",
    "        \"description\": \"Test DOT2\",\n",
    "\n",
    "        \"externalId\": \"202\",\n",
    "\n",
    "        \"initiativeId\": \"cd0eef61-5d45-4753-8436-ed12e113a94a\",\n",
    "\n",
    "        \"measureId\": \"2f4fffd9-2681-4719-93da-ee6add07fb70\",\n",
    "\n",
    "        \"metricId\": 101,\n",
    "\n",
    "        \"name\": \"Test DOT2\",\n",
    "\n",
    "        \"target\": 690,\n",
    "        \n",
    "        \"targetDate\": \"2021-07-30T00:00:00+0000\",\n",
    "\n",
    "        \"projections value\": 59,\n",
    "        \n",
    "        \"projections timestamp\": \"2021-07-30T00:00:00+0000\"\n",
    "    },\n",
    "    {\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-05T06:28:30.000Z\",\n",
    "\n",
    "        \"actuals value\": 281.2,\n",
    "\n",
    "        \"description\": \"Test DOT3\",\n",
    "\n",
    "        \"externalId\": \"203\",\n",
    "\n",
    "        \"initiativeId\": \"cd0eef61-5d45-4753-8436-ed12e113a94a\",\n",
    "\n",
    "        \"measureId\": \"2f4fffd9-2681-4719-93da-ee6add07fb70\",\n",
    "\n",
    "        \"metricId\": 101,\n",
    "\n",
    "        \"name\": \"Test DOT3\",\n",
    "\n",
    "        \"target\": 700,\n",
    "        \n",
    "        \"targetDate\": \"2021-07-30T00:00:00+0000\"\n",
    "    },\n",
    "    {\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-05T06:28:30.000Z\",\n",
    "\n",
    "        \"actuals value\": 291.2,\n",
    "\n",
    "        \"description\": \"Test DOT4\",\n",
    "\n",
    "        \"externalId\": \"204\",\n",
    "\n",
    "        \"initiativeId\": \"ee51bd64-3a19-45b9-83ed-4044f9e0b17e\",\n",
    "\n",
    "        \"measureId\": \"5230ceca-7528-4a72-a149-0f6499ec9db1\",\n",
    "\n",
    "        \"metricId\": 101,\n",
    "\n",
    "        \"name\": \"Test DOT4\",\n",
    "\n",
    "        \"target\": 800,\n",
    "        \n",
    "        \"targetDate\": \"2021-07-30T00:00:00+0000\"\n",
    "    }\n",
    "    \n",
    "]\n",
    "\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "\n",
    "    # By default : limit is set to 100\n",
    "    limit = 2\n",
    "    res = upsert_DOT(\n",
    "        token=token, dataframe=df, limit = limit)\n",
    "\n",
    "    assert res.status_code == 200\n",
    "    # assert (res.json()[\"created\"] == len(df.index) or\n",
    "    #         res.json()[\"updated\"] == len(df.index))\n",
    "    assert (res.json()[\"created\"] == limit or\n",
    "            res.json()[\"updated\"] == limit)\n",
    "\n",
    "\n",
    "def test_two_DOTs_correct_headers():\n",
    "    data = [{\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-05T06:28:30.000Z\",\n",
    "\n",
    "        \"actuals value\": 281.2,\n",
    "\n",
    "        \"description\": \"Test DOT1\",\n",
    "\n",
    "        \"externalId\": \"201\",\n",
    "\n",
    "        \"initiativeId\": np.NaN,\n",
    "\n",
    "        \"measureId\": np.NaN,\n",
    "\n",
    "        \"metricId\": 101,\n",
    "\n",
    "        \"name\": \"Test DOT1\",\n",
    "        \n",
    "        \"target\": 590,\n",
    "        \n",
    "        \"targetDate\": \"2021-07-30T00:00:00+0000\",\n",
    "\n",
    "        \"projections value\": 59,\n",
    "        \n",
    "        \"projections timestamp\": \"2021-07-30T00:00:00+0000\"\n",
    "    }]\n",
    "    # data = {\n",
    "    #             \"externalId\": [\"2343284\",\"73894792\"],\n",
    "    #             \"name\": [\"helloooooo\",\"helloooooo2\"],\n",
    "    #             \"description\": [\"sdklfjslfdjsldf\",\"sdklfjslfdjsldf\"],\n",
    "    #             \"metricId\": [10,10],\n",
    "    #             \"actuals\": [[\n",
    "    #                 {\n",
    "    #                         \"timestamp\": \"2021-12-07T14:59:38.273Z\",\n",
    "    #                         \"value\": 15\n",
    "    #                 }\n",
    "    #             ],\n",
    "    #             [\n",
    "    #                 {\n",
    "    #                         \"timestamp\": \"2021-12-07T14:59:38.273Z\",\n",
    "    #                         \"value\": 17\n",
    "    #                 }\n",
    "    #             ]],\n",
    "    #         }\n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    limit = 2\n",
    "    res = upsert_DOT(token = token,\n",
    "        dataframe= df, limit = limit\n",
    "    )\n",
    "\n",
    "    assert res.status_code == 200\n",
    "    assert (res.json()[\"created\"] == limit or\n",
    "            res.json()[\"updated\"] == limit)\n",
    "\n",
    "\n",
    "def test_null_DOTs():\n",
    "    data = [{\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-05T06:28:30.0002\",\n",
    "\n",
    "        \"actuals value\": 2,\n",
    "\n",
    "        \"description\": \"Test DOT1\",\n",
    "\n",
    "        \"externalId\": \"TD7\",\n",
    "\n",
    "        \"initiativeId\": \"9cc5c76f-7cc0-43e9-8f69-9549697c2955\",\n",
    "\n",
    "        \"metricId\": 10,\n",
    "\n",
    "        \"name\": \"Test DOT1\"\n",
    "    },\n",
    "    {\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-06T06:28:30.0001\",\n",
    "\n",
    "        \"actuals value\": 3,\n",
    "\n",
    "        \"description\": \"Test DOT2\",\n",
    "\n",
    "        \"externalId\": \"TD8\",\n",
    "\n",
    "        \"initiativeId\": \"9cc5c76f-7cc0-43e9-8f69-9549697c2955\",\n",
    "\n",
    "        \"metricId\": 10,\n",
    "\n",
    "        \"name\": \"Test DOT2\"\n",
    "    },\n",
    "    {\n",
    "\n",
    "        \"actuals timestamp\": \"2022-01-07T06:28:30.0000\",\n",
    "\n",
    "        \"actuals value\": 4,\n",
    "\n",
    "        \"description\": \"Test DOT3\",\n",
    "\n",
    "        \"externalId\": \"TD9\",\n",
    "\n",
    "        \"initiativeId\": \"9cc5c76f-7cc0-43e9-8f69-9549697c2955\",\n",
    "\n",
    "        \"metricId\": 10,\n",
    "\n",
    "        \"name\": \"Test DOT3\"\n",
    "    }]\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(data)\n",
    "    limit = 2\n",
    "    res = upsert_DOT(token = token,\n",
    "        dataframe= df, limit = limit\n",
    "    )\n",
    "\n",
    "    assert res.status_code == 200\n",
    "    assert (res.json()[\"created\"] == 1 or\n",
    "            res.json()[\"updated\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_DOT_correct_headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_two_DOTs_correct_headers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_null_DOTs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  externalId         name      description  metricId  \\\n",
      "0    2343284   helloooooo  sdklfjslfdjsldf        10   \n",
      "1   73894792  helloooooo2  sdklfjslfdjsldf        10   \n",
      "\n",
      "                                             actuals  \n",
      "0  [{'timestamp': '2021-12-07T14:59:38.273Z', 'va...  \n",
      "1  [{'timestamp': '2021-12-07T14:59:38.273Z', 'va...  \n"
     ]
    }
   ],
   "source": [
    "test_single_DOT_correct_headers()\n",
    "test_two_DOTs_correct_headers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This function still needs fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_object(\n",
    "#     token: str,\n",
    "#     object: str = \"digitalObjectTwins\",\n",
    "# ) -> list:\n",
    "#     \"\"\"Get JSON object.\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     token : str\n",
    "#         Token which was returned from the user login.\n",
    "#     object : str = \"dotTypes\"\n",
    "#         Object to be extracted from the API.\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     list\n",
    "#         List of JSON objects.\n",
    "\n",
    "#     Raises\n",
    "#     ------\n",
    "#     KeyError\n",
    "#         Raises KeyError when the input is not correct.\n",
    "#     \"\"\"\n",
    "#     url = getenv(\"CONNECT_URL\")\n",
    "\n",
    "#     if object == \"digitalObjectTwins\":\n",
    "#         url += \"/digitalObjectTwins/\"\n",
    "#     elif object == \"measures\":\n",
    "#         url += \"/measures/\"\n",
    "#     elif object == \"initiatives\":\n",
    "#         url += \"/initiatives/\"\n",
    "#     else:\n",
    "#         raise KeyError\n",
    "\n",
    "#     headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "#     response = requests.request(\"GET\", url, headers=headers)\n",
    "#     response.raise_for_status()\n",
    "#     return response.json()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fbf920807844ce4d636e293a8faa6802c83512ac71ec1d09800bef422842381"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit ('aioconnect_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
